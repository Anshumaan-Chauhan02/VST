{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s6i5qacKNuC"
   },
   "source": [
    "## Installing OpenAI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11727,
     "status": "ok",
     "timestamp": 1685885075345,
     "user": {
      "displayName": "Anshumaan Chauhan",
      "userId": "08247611702232216431"
     },
     "user_tz": 240
    },
    "id": "kaY1k1fOlGkE",
    "outputId": "3fa48fb3-327f-4a45-9c18-7c13cbf25f43",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 0.0/73.6 kB ? eta -:--:--\n",
      "     --------------------- ---------------- 41.0/73.6 kB 667.8 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 73.6/73.6 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\anshj\\anaconda3\\envs\\torch-gpu\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.8\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJgZjh6QzeX2"
   },
   "source": [
    "## Setting up ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WxY2My6wjKzp"
   },
   "outputs": [],
   "source": [
    "# Importing Operating System library\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4KiuukbnkdJ0"
   },
   "outputs": [],
   "source": [
    "# Setting the environment variable named \"OPENAI_API_KEY\" to the OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IktKrlxXk8Hk"
   },
   "outputs": [],
   "source": [
    "# Obtaining the api_key\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j71bo96UlI72"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "# Connecting to OpenAI API\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UU1jKuhzjGc"
   },
   "source": [
    "## Plot Generation using ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3SRyOkA2loiR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SyXZbQDelqNU"
   },
   "outputs": [],
   "source": [
    "# Loading the final processed dataset for plot generation\n",
    "df = pd.read_csv('Training_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(Plot=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qjUZB44SmL8W"
   },
   "outputs": [],
   "source": [
    "# Function to get the length of each summary \n",
    "def apply_len(x):\n",
    "  return len(x.split())\n",
    "df['len'] = df['Summary'].apply(apply_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFIeJ3zDnUzz"
   },
   "source": [
    "There's a hidden 500-word/4,000-character limit in ChatGPT for each individual input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FCUXiMWdmm8V"
   },
   "outputs": [],
   "source": [
    "# Filtering the summaries whose length is less than 450 words in order to match the ChatGPT limit\n",
    "df = df[df['len']<450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tiRhtX33nKA_"
   },
   "outputs": [],
   "source": [
    "# Different Instruction based prompts tested for plot generation\n",
    "prompt1 = \"Give a 1-2 line plot for the following summary: \"\n",
    "prompt2 = \"Based on the given summary, generate a 1-2 line plot: \"\n",
    "prompt3 = \"Generate a simple plain text 1-2 line plot for the given summary: \" # Best\n",
    "prompt4 = \"In 1-2 lines, briefly explain the plot of the following summary: \"\n",
    "prompt5 = \"In layman terms generate a 1-2 lines plot for the given summary: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kI4DpAjsnZOj"
   },
   "outputs": [],
   "source": [
    "# Function to send the request to ChatGPT and receive the generated plot\n",
    "def get_chatgpt_response(sample, prompt = prompt3):\n",
    "  completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": f\"{prompt} {sample}\"}\n",
    "  ])\n",
    "  return completion.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually the model is overloaded with requests (except at night), so avoid this\n",
    "df['Plot'] = df['Summary'].apply(get_chatgpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(i, df):\n",
    "    df['Plot'].iloc[i] = get_chatgpt_response(df['Summary'].iloc[i])\n",
    "    i+=1\n",
    "    return i, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "A1DdS-cKLQI3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshj\\AppData\\Local\\Temp\\ipykernel_14856\\777118137.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Plot'].iloc[i] = get_chatgpt_response(df['Summary'].iloc[i])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while i<len(df):\n",
    "    try:\n",
    "        i, df = plot_summary(i,df)\n",
    "    except:\n",
    "        i, df = plot_summary(i,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_text = lambda x: ' '.join([str(x['Input']), \"Plot:\", str(x['Plot'])])\n",
    "df['Input'] = df.apply(prepare_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Plot','len'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Plot_Summary_Dataset', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOP640TPmYEeFO9zqiMMyK1",
   "collapsed_sections": [
    "1s6i5qacKNuC",
    "JJgZjh6QzeX2"
   ],
   "mount_file_id": "10hwkAKqCmEtSheJG9NyXbXpUr6HtfUF7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (torch-gpu)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
